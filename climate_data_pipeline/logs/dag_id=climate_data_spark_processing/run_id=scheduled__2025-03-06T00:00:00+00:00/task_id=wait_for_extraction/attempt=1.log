[2025-03-07T16:32:03.524+0100] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-03-07T16:32:03.531+0100] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: climate_data_spark_processing.wait_for_extraction scheduled__2025-03-06T00:00:00+00:00 [queued]>
[2025-03-07T16:32:03.535+0100] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: climate_data_spark_processing.wait_for_extraction scheduled__2025-03-06T00:00:00+00:00 [queued]>
[2025-03-07T16:32:03.535+0100] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-03-07T16:32:03.543+0100] {taskinstance.py:2890} INFO - Executing <Task(ExternalTaskSensor): wait_for_extraction> on 2025-03-06 00:00:00+00:00
[2025-03-07T16:32:03.550+0100] {standard_task_runner.py:72} INFO - Started process 16476 to run task
[2025-03-07T16:32:03.555+0100] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'climate_data_spark_processing', 'wait_for_extraction', 'scheduled__2025-03-06T00:00:00+00:00', '--job-id', '78', '--raw', '--subdir', 'DAGS_FOLDER/spark-processing-dag.py', '--cfg-path', '/var/folders/55/x1yqz6851xj6j2f0smdhs4jh0000gn/T/tmpc36xoox7']
[2025-03-07T16:32:03.557+0100] {standard_task_runner.py:105} INFO - Job 78: Subtask wait_for_extraction
[2025-03-07T16:32:03.593+0100] {task_command.py:467} INFO - Running <TaskInstance: climate_data_spark_processing.wait_for_extraction scheduled__2025-03-06T00:00:00+00:00 [running]> on host gabis-imac-pro.local
[2025-03-07T16:32:03.629+0100] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='zoomcamp' AIRFLOW_CTX_DAG_ID='climate_data_spark_processing' AIRFLOW_CTX_TASK_ID='wait_for_extraction' AIRFLOW_CTX_EXECUTION_DATE='2025-03-06T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-03-06T00:00:00+00:00'
[2025-03-07T16:32:03.630+0100] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-03-07T16:32:03.631+0100] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-03-07T16:32:03.631+0100] {logging_mixin.py:190} INFO - Current task name:wait_for_extraction state:running start_date:2025-03-07 15:32:03.532103+00:00
[2025-03-07T16:32:03.631+0100] {logging_mixin.py:190} INFO - Dag name:climate_data_spark_processing and current dag run status:running
[2025-03-07T16:32:03.632+0100] {taskinstance.py:732} INFO - ::endgroup::
[2025-03-07T16:32:03.632+0100] {baseoperator.py:423} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-03-07T16:32:03.633+0100] {external_task.py:274} INFO - Poking for DAG 'climate_data_pipeline' on 2025-03-06T00:00:00+00:00 ... 
[2025-03-07T16:32:03.637+0100] {logging_mixin.py:190} WARNING - /usr/local/anaconda3/envs/airflow_env/lib/python3.8/site-packages/airflow/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-03-07T16:32:03.640+0100] {base.py:339} INFO - Success criteria met. Exiting.
[2025-03-07T16:32:03.643+0100] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-03-07T16:32:03.643+0100] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=climate_data_spark_processing, task_id=wait_for_extraction, run_id=scheduled__2025-03-06T00:00:00+00:00, execution_date=20250306T000000, start_date=20250307T153203, end_date=20250307T153203
[2025-03-07T16:32:03.652+0100] {logging_mixin.py:190} INFO - Task instance in success state
[2025-03-07T16:32:03.653+0100] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-03-07T16:32:03.653+0100] {logging_mixin.py:190} INFO - Dag name:climate_data_spark_processing queued_at:2025-03-07 15:32:00.817742+00:00
[2025-03-07T16:32:03.654+0100] {logging_mixin.py:190} INFO - Task hostname:gabis-imac-pro.local operator:ExternalTaskSensor
[2025-03-07T16:32:03.697+0100] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-03-07T16:32:03.719+0100] {taskinstance.py:3901} INFO - 2 downstream tasks scheduled from follow-on schedule check
[2025-03-07T16:32:03.720+0100] {local_task_job_runner.py:245} INFO - ::endgroup::
